{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "This notebook runs faster on a GPU runtime. To enable it, go to Edit > Notebook Settings > Hardware Accelerator > GPU.\n"
      ],
      "metadata": {
        "id": "Ptk1J307IVn8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "PqYLHVWoIgSe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)\n"
      ],
      "metadata": {
        "id": "IKXgOkl6Iabv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea126edd-e336-44b1-9bb3-0d3f20bed0ab"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.0+cu121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "import os\n",
        "\n",
        "os.environ['TORCH'] = torch.__version__\n",
        "!pip install pyg-lib -f https://data.pyg.org/whl/nightly/torch-${TORCH}.html\n",
        "!pip install git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "!pip install sentence_transformers\n",
        "!pip3 install fuzzywuzzy[speedup]\n",
        "!pip install captum"
      ],
      "metadata": {
        "id": "pV0Rkm6tIqcB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d77a86f-5eed-4c33-e46e-5612a823086b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/nightly/torch-2.5.0+cu121.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pyg-lib (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for pyg-lib\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting git+https://github.com/pyg-team/pytorch_geometric.git\n",
            "  Cloning https://github.com/pyg-team/pytorch_geometric.git to /tmp/pip-req-build-ic2g38dg\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/pyg-team/pytorch_geometric.git /tmp/pip-req-build-ic2g38dg\n",
            "  Resolved https://github.com/pyg-team/pytorch_geometric.git to commit facf0c404182b3b08eba0f8954906f7f01ef9eb5\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.10.10)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2024.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (3.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric==2.7.0) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (1.16.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric==2.7.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric==2.7.0) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric==2.7.0) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict<7.0,>=4.5->aiohttp->torch-geometric==2.7.0) (4.12.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->torch-geometric==2.7.0) (0.2.0)\n",
            "Building wheels for collected packages: torch-geometric\n",
            "  Building wheel for torch-geometric (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-geometric: filename=torch_geometric-2.7.0-py3-none-any.whl size=1136076 sha256=c29d80be9d525b952dd468291bf239f228e9a99c9507ccf867f9797ffc6da215\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-4k9was8r/wheels/d3/78/eb/9e26525b948d19533f1688fb6c209cec8a0ba793d39b49ae8f\n",
            "Successfully built torch-geometric\n",
            "Installing collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.44.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.5)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.5.0+cu121)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.5.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.24.7)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (10.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.20.0->sentence_transformers) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.4)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (1.26.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.8.30)\n",
            "Downloading sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m255.8/255.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentence_transformers\n",
            "Successfully installed sentence_transformers-3.2.1\n",
            "Collecting fuzzywuzzy[speedup]\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl.metadata (4.9 kB)\n",
            "Collecting python-levenshtein>=0.12 (from fuzzywuzzy[speedup])\n",
            "  Downloading python_Levenshtein-0.26.0-py3-none-any.whl.metadata (3.7 kB)\n",
            "Collecting Levenshtein==0.26.0 (from python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.2 kB)\n",
            "Collecting rapidfuzz<4.0.0,>=3.9.0 (from Levenshtein==0.26.0->python-levenshtein>=0.12->fuzzywuzzy[speedup])\n",
            "  Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Downloading python_Levenshtein-0.26.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading levenshtein-0.26.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading rapidfuzz-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: fuzzywuzzy, rapidfuzz, Levenshtein, python-levenshtein\n",
            "Successfully installed Levenshtein-0.26.0 fuzzywuzzy-0.18.0 python-levenshtein-0.26.0 rapidfuzz-3.10.1\n",
            "Collecting captum\n",
            "  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from captum) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from captum) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from captum) (2.5.0+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from captum) (4.66.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (2024.6.1)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->captum) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.6->captum) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (24.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->captum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->captum) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6->captum) (3.0.2)\n",
            "Downloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: captum\n",
            "Successfully installed captum-0.7.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Link Regression on the MovieLens Dataset\n",
        "\n",
        "This notebook shows how to load a set of `*.csv` files into a `torch_geometric.data.HeteroData` object and how to train a [heterogeneous graph model](https://pytorch-geometric.readthedocs.io/en/latest/notes/heterogeneous.html#hgtutorial).\n",
        "\n",
        "We are going to use the [Movielens dataset](https://grouplens.org/datasets/movielens/), which is collected by the GroupLens Research group. The toy dataset describes movies, users, and their ratings. We are going to predict the rating of a user for a movie."
      ],
      "metadata": {
        "id": "1WJ8piSnIy2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Ingestion"
      ],
      "metadata": {
        "id": "51OK1cQL9V9e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "EjJrBa3J0btD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the entire ratings dataframe into memory:\n",
        "data = pd.read_csv(\"/content/ChargingRecords.csv\")\n",
        "data"
      ],
      "metadata": {
        "id": "dXCWG11MYCSz",
        "outputId": "df56e86a-d80a-4dd9-bca1-acb3bbc53204",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       UserID  ChargerID  ChargerCompany            Location  ChargerType  \\\n",
              "0           0          1               1               hotel            0   \n",
              "1           0          1               1               hotel            0   \n",
              "2           0          1               1               hotel            0   \n",
              "3           0          1               1               hotel            0   \n",
              "4           0          1               1               hotel            0   \n",
              "...       ...        ...             ...                 ...          ...   \n",
              "72851    2155       2649               0  public institution            0   \n",
              "72852    2379       2670               0         sightseeing            1   \n",
              "72853    2388       2670               0         sightseeing            1   \n",
              "72854    2388       2671               0             company            1   \n",
              "72855    2388       2671               0             company            1   \n",
              "\n",
              "         StartDay StartTime      EndDay   EndTime     StartDatetime  \\\n",
              "0      2022-09-15  20:54:02  2022-09-15  23:59:13  2022-09-15 20:54   \n",
              "1      2022-09-14  20:01:05  2022-09-14  21:31:04  2022-09-14 20:01   \n",
              "2      2022-09-14  18:54:30  2022-09-14  19:54:29  2022-09-14 18:54   \n",
              "3      2022-09-29  18:32:51  2022-09-30   0:16:42  2022-09-29 18:32   \n",
              "4      2022-09-25  19:30:15  2022-09-26   0:30:14  2022-09-25 19:30   \n",
              "...           ...       ...         ...       ...               ...   \n",
              "72851  2022-01-27   9:54:44  2022-01-27   9:58:57   2022-01-27 9:54   \n",
              "72852  2021-10-31  14:52:11  2021-10-31  15:20:28  2021-10-31 14:52   \n",
              "72853  2021-10-03  13:52:14  2021-10-03  14:32:13  2021-10-03 13:52   \n",
              "72854  2021-11-18  11:37:44  2021-11-18  11:45:37  2021-11-18 11:37   \n",
              "72855  2021-10-30  17:29:02  2021-10-30  17:36:47  2021-10-30 17:29   \n",
              "\n",
              "            EndDatetime  Duration  Demand  \n",
              "0      2022-09-15 23:59       185   20.36  \n",
              "1      2022-09-14 21:31        90   10.19  \n",
              "2      2022-09-14 19:54        60    6.78  \n",
              "3       2022-09-30 0:16       344   37.65  \n",
              "4       2022-09-26 0:30       300   33.81  \n",
              "...                 ...       ...     ...  \n",
              "72851   2022-01-27 9:58         4    0.50  \n",
              "72852  2021-10-31 15:20        28   16.53  \n",
              "72853  2021-10-03 14:32        40   12.20  \n",
              "72854  2021-11-18 11:45         8    3.80  \n",
              "72855  2021-10-30 17:36         8    3.67  \n",
              "\n",
              "[72856 rows x 13 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c887ca9f-cd0b-4b7a-8399-7703b773a6e5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UserID</th>\n",
              "      <th>ChargerID</th>\n",
              "      <th>ChargerCompany</th>\n",
              "      <th>Location</th>\n",
              "      <th>ChargerType</th>\n",
              "      <th>StartDay</th>\n",
              "      <th>StartTime</th>\n",
              "      <th>EndDay</th>\n",
              "      <th>EndTime</th>\n",
              "      <th>StartDatetime</th>\n",
              "      <th>EndDatetime</th>\n",
              "      <th>Duration</th>\n",
              "      <th>Demand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hotel</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-09-15</td>\n",
              "      <td>20:54:02</td>\n",
              "      <td>2022-09-15</td>\n",
              "      <td>23:59:13</td>\n",
              "      <td>2022-09-15 20:54</td>\n",
              "      <td>2022-09-15 23:59</td>\n",
              "      <td>185</td>\n",
              "      <td>20.36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hotel</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-09-14</td>\n",
              "      <td>20:01:05</td>\n",
              "      <td>2022-09-14</td>\n",
              "      <td>21:31:04</td>\n",
              "      <td>2022-09-14 20:01</td>\n",
              "      <td>2022-09-14 21:31</td>\n",
              "      <td>90</td>\n",
              "      <td>10.19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hotel</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-09-14</td>\n",
              "      <td>18:54:30</td>\n",
              "      <td>2022-09-14</td>\n",
              "      <td>19:54:29</td>\n",
              "      <td>2022-09-14 18:54</td>\n",
              "      <td>2022-09-14 19:54</td>\n",
              "      <td>60</td>\n",
              "      <td>6.78</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hotel</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-09-29</td>\n",
              "      <td>18:32:51</td>\n",
              "      <td>2022-09-30</td>\n",
              "      <td>0:16:42</td>\n",
              "      <td>2022-09-29 18:32</td>\n",
              "      <td>2022-09-30 0:16</td>\n",
              "      <td>344</td>\n",
              "      <td>37.65</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>hotel</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-09-25</td>\n",
              "      <td>19:30:15</td>\n",
              "      <td>2022-09-26</td>\n",
              "      <td>0:30:14</td>\n",
              "      <td>2022-09-25 19:30</td>\n",
              "      <td>2022-09-26 0:30</td>\n",
              "      <td>300</td>\n",
              "      <td>33.81</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72851</th>\n",
              "      <td>2155</td>\n",
              "      <td>2649</td>\n",
              "      <td>0</td>\n",
              "      <td>public institution</td>\n",
              "      <td>0</td>\n",
              "      <td>2022-01-27</td>\n",
              "      <td>9:54:44</td>\n",
              "      <td>2022-01-27</td>\n",
              "      <td>9:58:57</td>\n",
              "      <td>2022-01-27 9:54</td>\n",
              "      <td>2022-01-27 9:58</td>\n",
              "      <td>4</td>\n",
              "      <td>0.50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72852</th>\n",
              "      <td>2379</td>\n",
              "      <td>2670</td>\n",
              "      <td>0</td>\n",
              "      <td>sightseeing</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-10-31</td>\n",
              "      <td>14:52:11</td>\n",
              "      <td>2021-10-31</td>\n",
              "      <td>15:20:28</td>\n",
              "      <td>2021-10-31 14:52</td>\n",
              "      <td>2021-10-31 15:20</td>\n",
              "      <td>28</td>\n",
              "      <td>16.53</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72853</th>\n",
              "      <td>2388</td>\n",
              "      <td>2670</td>\n",
              "      <td>0</td>\n",
              "      <td>sightseeing</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-10-03</td>\n",
              "      <td>13:52:14</td>\n",
              "      <td>2021-10-03</td>\n",
              "      <td>14:32:13</td>\n",
              "      <td>2021-10-03 13:52</td>\n",
              "      <td>2021-10-03 14:32</td>\n",
              "      <td>40</td>\n",
              "      <td>12.20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72854</th>\n",
              "      <td>2388</td>\n",
              "      <td>2671</td>\n",
              "      <td>0</td>\n",
              "      <td>company</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-11-18</td>\n",
              "      <td>11:37:44</td>\n",
              "      <td>2021-11-18</td>\n",
              "      <td>11:45:37</td>\n",
              "      <td>2021-11-18 11:37</td>\n",
              "      <td>2021-11-18 11:45</td>\n",
              "      <td>8</td>\n",
              "      <td>3.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72855</th>\n",
              "      <td>2388</td>\n",
              "      <td>2671</td>\n",
              "      <td>0</td>\n",
              "      <td>company</td>\n",
              "      <td>1</td>\n",
              "      <td>2021-10-30</td>\n",
              "      <td>17:29:02</td>\n",
              "      <td>2021-10-30</td>\n",
              "      <td>17:36:47</td>\n",
              "      <td>2021-10-30 17:29</td>\n",
              "      <td>2021-10-30 17:36</td>\n",
              "      <td>8</td>\n",
              "      <td>3.67</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>72856 rows × 13 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c887ca9f-cd0b-4b7a-8399-7703b773a6e5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c887ca9f-cd0b-4b7a-8399-7703b773a6e5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c887ca9f-cd0b-4b7a-8399-7703b773a6e5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-82b2a4da-348c-4430-b034-8a201b971fcc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-82b2a4da-348c-4430-b034-8a201b971fcc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-82b2a4da-348c-4430-b034-8a201b971fcc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_6f0bdb90-2f3d-44ab-990b-027743bb5889\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_6f0bdb90-2f3d-44ab-990b-027743bb5889 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 72856,\n  \"fields\": [\n    {\n      \"column\": \"UserID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 553,\n        \"min\": 0,\n        \"max\": 2501,\n        \"num_unique_values\": 2337,\n        \"samples\": [\n          25,\n          833,\n          1570\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ChargerID\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 569,\n        \"min\": 1,\n        \"max\": 2671,\n        \"num_unique_values\": 2119,\n        \"samples\": [\n          2098,\n          529,\n          883\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ChargerCompany\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Location\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"sightseeing\",\n          \"camping\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ChargerType\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"StartDay\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 366,\n        \"samples\": [\n          \"2022-04-13\",\n          \"2022-05-23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"StartTime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 43245,\n        \"samples\": [\n          \"17:15:41\",\n          \"12:57:52\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EndDay\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 365,\n        \"samples\": [\n          \"2022-03-23\",\n          \"2022-05-23\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EndTime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 46710,\n        \"samples\": [\n          \"9:40:59\",\n          \"11:45:38\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"StartDatetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 65628,\n        \"samples\": [\n          \"2022-06-15 23:05\",\n          \"2021-11-24 20:31\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"EndDatetime\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 66745,\n        \"samples\": [\n          \"2022-04-06 22:51\",\n          \"2022-06-11 1:32\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 146,\n        \"min\": -29,\n        \"max\": 1573,\n        \"num_unique_values\": 979,\n        \"samples\": [\n          159,\n          444\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Demand\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13.492728126855202,\n        \"min\": 0.01,\n        \"max\": 97.0,\n        \"num_unique_values\": 6046,\n        \"samples\": [\n          1.66,\n          48.66\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "We are going to use the genre as well as the title of the movie as node features. For the `title` features, we are going to use a pre-trained [sentence transformer](https://www.sbert.net/) model to encode the title into a vector.\n",
        "For the `genre` features, we are going to use a one-hot encoding."
      ],
      "metadata": {
        "id": "0uhaQNVsI76a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "# One-hot encode the genres:\n",
        "Locations = data['Location'].str.get_dummies().values\n",
        "Locations = torch.from_numpy(Locations).to(torch.float)"
      ],
      "metadata": {
        "id": "2esCQBOoYxcZ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data['Location'].unique())"
      ],
      "metadata": {
        "id": "k_rrhiz6ZLqu",
        "outputId": "b61f4824-a1e3-490d-972c-1d090dbedfca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Locations.shape"
      ],
      "metadata": {
        "id": "DERlI5XkZCLN",
        "outputId": "f63bc36b-fb74-4e61-90e4-6eb77b365787",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([72856, 14])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ChargerCompany = torch.from_numpy(data['ChargerCompany'].values).to(torch.float)"
      ],
      "metadata": {
        "id": "7H_3BlwqZuFT"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChargerType = torch.from_numpy(data['ChargerType'].values).to(torch.float)"
      ],
      "metadata": {
        "id": "YEK_PiGSat4q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ChargerCompany.unsqueeze(-1)"
      ],
      "metadata": {
        "id": "ZogHwAn0binD",
        "outputId": "ee0f96e7-dee0-487f-8222-072379db384f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.],\n",
              "        [1.],\n",
              "        [1.],\n",
              "        ...,\n",
              "        [0.],\n",
              "        [0.],\n",
              "        [0.]])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenate the genres and title features:\n",
        "station_features = torch.cat([Locations, ChargerCompany.unsqueeze(-1),ChargerType.unsqueeze(-1)], dim=-1)\n",
        "\n",
        "# We don't have user features, which is why we use an identity matrix\n",
        "ev_features = torch.eye(len(data['UserID'].unique()))\n"
      ],
      "metadata": {
        "id": "fXF-BNIYJAMo"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ev_features.shape"
      ],
      "metadata": {
        "id": "O0sa4F9Mb91A",
        "outputId": "4d01b161-8003-41ac-a916-6ec84782ee35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2337, 2337])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `ratings.csv` file contains the ratings of users for movies. From this\n",
        "file we are extracting the `userId`. We create a mapping from the `userId`\n",
        "to a unique consecutive value in the range `[0, num_users]`. This is needed as we want our final data representation to be as compact as possible, *e.g.*, the representation of a user in the first row should be accessible via `x[0]`.\n",
        "The same we do for the `movieId`.\n",
        "Afterwards, we obtain the final `edge_index` representation of shape `[2, num_ratings]` from `ratings.csv` by merging mapped user and movie indices with the raw indices given by the original data frame.\n"
      ],
      "metadata": {
        "id": "1cHyIhDgJCZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a mapping from the userId to a unique consecutive value in the range [0, num_users]:\n",
        "unique_user_id = data['UserID'].unique()\n",
        "unique_user_id = pd.DataFrame(data={\n",
        "    'UserID': unique_user_id,\n",
        "    'mappedUserId': pd.RangeIndex(len(unique_user_id))\n",
        "    })\n",
        "print(\"Mapping of user IDs to consecutive values:\")\n",
        "print(\"==========================================\")\n",
        "print(unique_user_id.head())\n",
        "print()\n",
        "\n",
        "# Create a mapping from the movieId to a unique consecutive value in the range [0, num_movies]:\n",
        "unique_movie_id = data['ChargerID'].unique()\n",
        "unique_movie_id = pd.DataFrame(data={\n",
        "    'ChargerID': unique_movie_id,\n",
        "    'mappedMovieId': pd.RangeIndex(len(unique_movie_id))\n",
        "    })\n",
        "print(\"Mapping of movie IDs to consecutive values:\")\n",
        "print(\"===========================================\")\n",
        "print(unique_movie_id.head())\n",
        "print()\n",
        "\n",
        "# Merge the mappings with the original data frame:\n",
        "data = data.merge(unique_user_id, on='UserID')\n",
        "data = data.merge(unique_movie_id, on='ChargerID')\n",
        "\n",
        "# With this, we are ready to create the edge_index representation in COO format\n",
        "# following the PyTorch Geometric semantics:\n",
        "edge_index = torch.stack([\n",
        "    torch.tensor(data['mappedUserId'].values),\n",
        "    torch.tensor(data['mappedMovieId'].values)]\n",
        "    , dim=0)\n",
        "\n",
        "assert edge_index.shape == (2, len(data))\n",
        "\n",
        "print(\"Final edge indices pointing from users to movies:\")\n",
        "print(\"================================================\")\n",
        "print(edge_index[:, :10])"
      ],
      "metadata": {
        "id": "_7YZJLJVJEbL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb0f023-c836-415a-b446-548ebc9c0d68"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of user IDs to consecutive values:\n",
            "==========================================\n",
            "   UserID  mappedUserId\n",
            "0       0             0\n",
            "1      14             1\n",
            "2     156             2\n",
            "3     246             3\n",
            "4     330             4\n",
            "\n",
            "Mapping of movie IDs to consecutive values:\n",
            "===========================================\n",
            "   ChargerID  mappedMovieId\n",
            "0          1              0\n",
            "1          2              1\n",
            "2          3              2\n",
            "3          5              3\n",
            "4          7              4\n",
            "\n",
            "Final edge indices pointing from users to movies:\n",
            "================================================\n",
            "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(edge_index[:, -10:])"
      ],
      "metadata": {
        "id": "Y7szmzV9f1M1",
        "outputId": "138f53fe-3ce7-44fa-e3af-e1cd03911a20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2334, 1703, 1304, 2335, 2335, 2336, 1976, 1458, 1458, 1458],\n",
            "        [2112, 2113, 2114, 2115, 2115, 2116, 2117, 2117, 2118, 2118]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Heterogeneous Graph Construction\n",
        "\n",
        "With this we are ready to initialize our heterogeneous graph data object and pass the\n",
        "necessary information to it.\n",
        "\n",
        "We also take care of adding reverse edges to the `HeteroData` object. This allows our GNN\n",
        "model to use both directions of the edges for the message passing."
      ],
      "metadata": {
        "id": "HfnycIvfJHrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "id": "OxTUBjWjghIm",
        "outputId": "cb484969-fe23-45a8-eb2c-0f932e7f90e0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['UserID', 'ChargerID', 'ChargerCompany', 'Location', 'ChargerType',\n",
              "       'StartDay', 'StartTime', 'EndDay', 'EndTime', 'StartDatetime',\n",
              "       'EndDatetime', 'Duration', 'Demand', 'mappedUserId', 'mappedMovieId'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.data import HeteroData\n",
        "\n",
        "# Create the heterogeneous graph data object:\n",
        "Hdata = HeteroData()\n",
        "\n",
        "# Add the user nodes:\n",
        "Hdata['user'].x = ev_features  # [num_users, num_features_users]\n",
        "\n",
        "# Add the movie nodes:\n",
        "Hdata['station'].x = station_features  # [num_movies, num_features_movies]\n",
        "\n",
        "# Add the rating edges:\n",
        "Hdata['user', 'demand', 'station'].edge_index = edge_index  # [2, num_ratings]\n",
        "\n",
        "# Add the rating labels:\n",
        "Demand = torch.from_numpy(data['Demand'].values).to(torch.float)\n",
        "Hdata['user', 'demand', 'station'].edge_label = Demand  # [num_ratings]\n",
        "\n",
        "# We also need to make sure to add the reverse edges from movies to users\n",
        "# in order to let a GNN be able to pass messages in both directions.\n",
        "# We can leverage the `T.ToUndirected()` transform for this from PyG:\n",
        "Hdata = T.ToUndirected()(Hdata)\n",
        "\n",
        "# With the above transformation we also got reversed labels for the edges.\n",
        "# We are going to remove them:\n",
        "del Hdata['station', 'rev_demand', 'user'].edge_label\n",
        "\n",
        "assert Hdata['user'].num_nodes == len(unique_user_id)\n",
        "assert Hdata['user', 'demand', 'station'].num_edges == len(data)\n",
        "assert Hdata['station'].num_features == 16\n",
        "\n",
        "Hdata"
      ],
      "metadata": {
        "id": "cDQaX8OPJMvj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66f929c5-7f11-4215-bd08-0f81fbd17ecd"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  user={ x=[2337, 2337] },\n",
              "  station={ x=[72856, 16] },\n",
              "  (user, demand, station)={\n",
              "    edge_index=[2, 72856],\n",
              "    edge_label=[72856],\n",
              "  },\n",
              "  (station, rev_demand, user)={ edge_index=[2, 72856] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Splitting\n",
        "\n",
        "We can now split our data into a training, validation and test set. We are going to use\n",
        "the `T.RandomLinkSplit` transform from PyG to do this. This transform will randomly\n",
        "split the links with their label/demand into training, validation and test set.\n",
        "We are going to use 80% of the edges for training, 10% for validation and 10% for testing."
      ],
      "metadata": {
        "id": "qpcH0bniJaJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('user', 'demand', 'station')],\n",
        "    rev_edge_types=[('station', 'rev_demand', 'user')],\n",
        ")(Hdata)\n",
        "train_data, val_data"
      ],
      "metadata": {
        "id": "njo191z3JctD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87276682-2c31-4607-fd7a-6631d49a3733"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(HeteroData(\n",
              "   user={ x=[2337, 2337] },\n",
              "   station={ x=[72856, 16] },\n",
              "   (user, demand, station)={\n",
              "     edge_index=[2, 58286],\n",
              "     edge_label=[58286],\n",
              "     edge_label_index=[2, 58286],\n",
              "   },\n",
              "   (station, rev_demand, user)={ edge_index=[2, 58286] }\n",
              " ),\n",
              " HeteroData(\n",
              "   user={ x=[2337, 2337] },\n",
              "   station={ x=[72856, 16] },\n",
              "   (user, demand, station)={\n",
              "     edge_index=[2, 58286],\n",
              "     edge_label=[7285],\n",
              "     edge_label_index=[2, 7285],\n",
              "   },\n",
              "   (station, rev_demand, user)={ edge_index=[2, 58286] }\n",
              " ))"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Graph Neural Network\n",
        "\n",
        "We are now ready to define our GNN model. We are going to use a simple GNN model with\n",
        "two message passing layers for the encoding of the user and movie nodes.\n",
        "Additionally, we are going to use a decoder to predict the rating for the encoded\n",
        "user-station combination."
      ],
      "metadata": {
        "id": "xfg4wVcNJfFY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, to_hetero\n",
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = torch.nn.Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = torch.nn.Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['user'][row], z_dict['station'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, Hdata.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = Model(hidden_channels=32).to(device)\n",
        "\n",
        "print(model)"
      ],
      "metadata": {
        "id": "fl5W1gg5Jhzz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24915a9c-89bc-401b-a4a6-50f34ccf0a5f"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model(\n",
            "  (encoder): GraphModule(\n",
            "    (conv1): ModuleDict(\n",
            "      (user__demand__station): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "      (station__rev_demand__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "    )\n",
            "    (conv2): ModuleDict(\n",
            "      (user__demand__station): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "      (station__rev_demand__user): SAGEConv((-1, -1), 32, aggr=mean)\n",
            "    )\n",
            "  )\n",
            "  (decoder): EdgeDecoder(\n",
            "    (lin1): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (lin2): Linear(in_features=32, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training a Heterogeneous GNN\n",
        "\n",
        "Training our GNN is then similar to training any PyTorch model.\n",
        "We move the model to the desired device, and initialize an optimizer that takes care of adjusting model parameters via stochastic gradient descent.\n",
        "\n",
        "The training loop applies the forward computation of the model, computes the loss from ground-truth labels and obtained predictions, and adjusts model parameters via back-propagation and stochastic gradient descent.\n"
      ],
      "metadata": {
        "id": "azGW0k2pJoS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['user', 'station'].edge_label_index)\n",
        "    target = train_data['user', 'station'].edge_label\n",
        "    loss = F.mse_loss(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    data = data.to(device)\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['user', 'station'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=5)\n",
        "    target = data['user', 'station'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "\n",
        "\n",
        "for epoch in range(1, 301):\n",
        "    train_data = train_data.to(device)\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}')"
      ],
      "metadata": {
        "id": "_5_rbeCjJnsz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51742fb1-7f02-4d6a-a129-f1baa46532bb"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 489.5347, Train: 22.0008, Val: 22.2866\n",
            "Epoch: 002, Loss: 484.0378, Train: 21.8183, Val: 22.1042\n",
            "Epoch: 003, Loss: 476.0367, Train: 21.5400, Val: 21.8258\n",
            "Epoch: 004, Loss: 463.9698, Train: 21.1076, Val: 21.3935\n",
            "Epoch: 005, Loss: 445.5321, Train: 20.4557, Val: 20.7415\n",
            "Epoch: 006, Loss: 418.4375, Train: 19.5260, Val: 19.8106\n",
            "Epoch: 007, Loss: 381.2643, Train: 18.3539, Val: 18.6341\n",
            "Epoch: 008, Loss: 333.4708, Train: 18.3303, Val: 18.5934\n",
            "Epoch: 009, Loss: 277.3129, Train: 18.3303, Val: 18.5890\n",
            "Epoch: 010, Loss: 220.9105, Train: 18.3303, Val: 18.5885\n",
            "Epoch: 011, Loss: 183.6581, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 012, Loss: 198.4483, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 013, Loss: 244.4870, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 014, Loss: 244.7488, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 015, Loss: 214.6815, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 016, Loss: 186.3483, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 017, Loss: 173.6774, Train: 18.3303, Val: 18.5885\n",
            "Epoch: 018, Loss: 174.8454, Train: 18.3303, Val: 18.5886\n",
            "Epoch: 019, Loss: 182.3307, Train: 18.3303, Val: 18.5887\n",
            "Epoch: 020, Loss: 189.7678, Train: 18.3303, Val: 18.5888\n",
            "Epoch: 021, Loss: 193.7851, Train: 18.3303, Val: 18.5888\n",
            "Epoch: 022, Loss: 193.2850, Train: 18.3303, Val: 18.5887\n",
            "Epoch: 023, Loss: 188.5953, Train: 18.3303, Val: 18.5887\n",
            "Epoch: 024, Loss: 180.9031, Train: 18.3303, Val: 18.5885\n",
            "Epoch: 025, Loss: 172.0506, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 026, Loss: 164.3163, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 027, Loss: 159.8943, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 028, Loss: 159.8572, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 029, Loss: 162.9921, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 030, Loss: 165.9114, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 031, Loss: 165.4360, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 032, Loss: 161.2092, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 033, Loss: 155.5373, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 034, Loss: 151.0637, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 035, Loss: 148.9669, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 036, Loss: 148.8010, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 037, Loss: 149.3208, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 038, Loss: 149.3275, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 039, Loss: 148.1447, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 040, Loss: 145.7886, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 041, Loss: 142.8152, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 042, Loss: 140.0718, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 043, Loss: 138.3063, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 044, Loss: 137.6975, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 045, Loss: 137.6446, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 046, Loss: 137.1164, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 047, Loss: 135.6462, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 048, Loss: 133.6362, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 049, Loss: 131.8527, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 050, Loss: 130.7187, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 051, Loss: 130.1483, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 052, Loss: 129.7742, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 053, Loss: 129.2305, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 054, Loss: 128.3799, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 055, Loss: 127.3554, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 056, Loss: 126.4339, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 057, Loss: 125.8349, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 058, Loss: 125.5519, Train: 18.3303, Val: 18.5884\n",
            "Epoch: 059, Loss: 125.3589, Train: 18.3303, Val: 18.5883\n",
            "Epoch: 060, Loss: 125.0151, Train: 18.3302, Val: 18.5883\n",
            "Epoch: 061, Loss: 124.4815, Train: 18.3302, Val: 18.5882\n",
            "Epoch: 062, Loss: 123.9228, Train: 18.3302, Val: 18.5882\n",
            "Epoch: 063, Loss: 123.5210, Train: 18.3302, Val: 18.5882\n",
            "Epoch: 064, Loss: 123.3111, Train: 18.3303, Val: 18.5882\n",
            "Epoch: 065, Loss: 123.1846, Train: 18.3303, Val: 18.5882\n",
            "Epoch: 066, Loss: 123.0061, Train: 18.3303, Val: 18.5882\n",
            "Epoch: 067, Loss: 122.7218, Train: 18.3302, Val: 18.5882\n",
            "Epoch: 068, Loss: 122.3860, Train: 18.3302, Val: 18.5881\n",
            "Epoch: 069, Loss: 122.1004, Train: 18.3302, Val: 18.5881\n",
            "Epoch: 070, Loss: 121.9207, Train: 18.3302, Val: 18.5881\n",
            "Epoch: 071, Loss: 121.8114, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 072, Loss: 121.6831, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 073, Loss: 121.4870, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 074, Loss: 121.2606, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 075, Loss: 121.0726, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 076, Loss: 120.9499, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 077, Loss: 120.8643, Train: 18.3301, Val: 18.5880\n",
            "Epoch: 078, Loss: 120.7676, Train: 18.3301, Val: 18.5879\n",
            "Epoch: 079, Loss: 120.6389, Train: 18.3301, Val: 18.5879\n",
            "Epoch: 080, Loss: 120.4981, Train: 18.3301, Val: 18.5879\n",
            "Epoch: 081, Loss: 120.3795, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 082, Loss: 120.2952, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 083, Loss: 120.2258, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 084, Loss: 120.1425, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 085, Loss: 120.0366, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 086, Loss: 119.9253, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 087, Loss: 119.8283, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 088, Loss: 119.7474, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 089, Loss: 119.6670, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 090, Loss: 119.5738, Train: 18.3300, Val: 18.5879\n",
            "Epoch: 091, Loss: 119.4692, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 092, Loss: 119.3653, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 093, Loss: 119.2710, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 094, Loss: 119.1827, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 095, Loss: 119.0901, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 096, Loss: 118.9880, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 097, Loss: 118.8814, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 098, Loss: 118.7775, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 099, Loss: 118.6777, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 100, Loss: 118.5767, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 101, Loss: 118.4692, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 102, Loss: 118.3559, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 103, Loss: 118.2410, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 104, Loss: 118.1274, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 105, Loss: 118.0128, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 106, Loss: 117.8931, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 107, Loss: 117.7676, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 108, Loss: 117.6393, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 109, Loss: 117.5106, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 110, Loss: 117.3803, Train: 18.3300, Val: 18.5878\n",
            "Epoch: 111, Loss: 117.2465, Train: 18.3299, Val: 18.5878\n",
            "Epoch: 112, Loss: 117.1087, Train: 18.3299, Val: 18.5878\n",
            "Epoch: 113, Loss: 116.9681, Train: 18.3299, Val: 18.5878\n",
            "Epoch: 114, Loss: 116.8262, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 115, Loss: 116.6824, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 116, Loss: 116.5355, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 117, Loss: 116.3861, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 118, Loss: 116.2347, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 119, Loss: 116.0816, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 120, Loss: 115.9264, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 121, Loss: 115.7692, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 122, Loss: 115.6100, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 123, Loss: 115.4498, Train: 18.3299, Val: 18.5879\n",
            "Epoch: 124, Loss: 115.2888, Train: 18.3299, Val: 18.5880\n",
            "Epoch: 125, Loss: 115.1279, Train: 18.3299, Val: 18.5880\n",
            "Epoch: 126, Loss: 114.9655, Train: 18.3299, Val: 18.5880\n",
            "Epoch: 127, Loss: 114.8028, Train: 18.3299, Val: 18.5880\n",
            "Epoch: 128, Loss: 114.6404, Train: 18.3299, Val: 18.5881\n",
            "Epoch: 129, Loss: 114.4781, Train: 18.3299, Val: 18.5881\n",
            "Epoch: 130, Loss: 114.3158, Train: 18.3300, Val: 18.5882\n",
            "Epoch: 131, Loss: 114.1538, Train: 18.3300, Val: 18.5882\n",
            "Epoch: 132, Loss: 113.9931, Train: 18.3300, Val: 18.5883\n",
            "Epoch: 133, Loss: 113.8331, Train: 18.3300, Val: 18.5883\n",
            "Epoch: 134, Loss: 113.6739, Train: 18.3300, Val: 18.5884\n",
            "Epoch: 135, Loss: 113.5208, Train: 18.3300, Val: 18.5885\n",
            "Epoch: 136, Loss: 113.3596, Train: 18.3301, Val: 18.5885\n",
            "Epoch: 137, Loss: 113.2054, Train: 18.3301, Val: 18.5886\n",
            "Epoch: 138, Loss: 113.0528, Train: 18.3301, Val: 18.5887\n",
            "Epoch: 139, Loss: 112.9025, Train: 18.3302, Val: 18.5888\n",
            "Epoch: 140, Loss: 112.7547, Train: 18.3302, Val: 18.5888\n",
            "Epoch: 141, Loss: 112.6077, Train: 18.3303, Val: 18.5889\n",
            "Epoch: 142, Loss: 112.4602, Train: 18.3303, Val: 18.5890\n",
            "Epoch: 143, Loss: 112.3095, Train: 18.3304, Val: 18.5891\n",
            "Epoch: 144, Loss: 112.1555, Train: 18.3304, Val: 18.5892\n",
            "Epoch: 145, Loss: 111.9971, Train: 18.3305, Val: 18.5893\n",
            "Epoch: 146, Loss: 111.8351, Train: 18.3306, Val: 18.5893\n",
            "Epoch: 147, Loss: 111.6711, Train: 18.3306, Val: 18.5894\n",
            "Epoch: 148, Loss: 111.5078, Train: 18.3307, Val: 18.5895\n",
            "Epoch: 149, Loss: 111.3462, Train: 18.3308, Val: 18.5896\n",
            "Epoch: 150, Loss: 111.1904, Train: 18.3309, Val: 18.5897\n",
            "Epoch: 151, Loss: 111.0346, Train: 18.3310, Val: 18.5900\n",
            "Epoch: 152, Loss: 110.8670, Train: 18.3311, Val: 18.5903\n",
            "Epoch: 153, Loss: 110.7007, Train: 18.3312, Val: 18.5906\n",
            "Epoch: 154, Loss: 110.5254, Train: 18.3313, Val: 18.5908\n",
            "Epoch: 155, Loss: 110.3699, Train: 18.3314, Val: 18.5912\n",
            "Epoch: 156, Loss: 110.2152, Train: 18.3316, Val: 18.5917\n",
            "Epoch: 157, Loss: 110.0638, Train: 18.3317, Val: 18.5922\n",
            "Epoch: 158, Loss: 109.9181, Train: 18.3319, Val: 18.5928\n",
            "Epoch: 159, Loss: 109.7598, Train: 18.3320, Val: 18.5933\n",
            "Epoch: 160, Loss: 109.6181, Train: 18.3318, Val: 18.5931\n",
            "Epoch: 161, Loss: 109.4642, Train: 18.3317, Val: 18.5931\n",
            "Epoch: 162, Loss: 109.3584, Train: 18.3320, Val: 18.5942\n",
            "Epoch: 163, Loss: 109.2630, Train: 18.3318, Val: 18.5939\n",
            "Epoch: 164, Loss: 109.0649, Train: 18.3316, Val: 18.5937\n",
            "Epoch: 165, Loss: 109.0126, Train: 18.3316, Val: 18.5941\n",
            "Epoch: 166, Loss: 108.8226, Train: 18.3316, Val: 18.5941\n",
            "Epoch: 167, Loss: 108.7384, Train: 18.3311, Val: 18.5930\n",
            "Epoch: 168, Loss: 108.5365, Train: 18.3307, Val: 18.5918\n",
            "Epoch: 169, Loss: 108.4790, Train: 18.3307, Val: 18.5921\n",
            "Epoch: 170, Loss: 108.2957, Train: 18.3307, Val: 18.5924\n",
            "Epoch: 171, Loss: 108.2084, Train: 18.3304, Val: 18.5919\n",
            "Epoch: 172, Loss: 108.0528, Train: 18.3303, Val: 18.5913\n",
            "Epoch: 173, Loss: 107.9677, Train: 18.3302, Val: 18.5912\n",
            "Epoch: 174, Loss: 107.8131, Train: 18.3300, Val: 18.5908\n",
            "Epoch: 175, Loss: 107.7159, Train: 18.3298, Val: 18.5900\n",
            "Epoch: 176, Loss: 107.5724, Train: 18.3297, Val: 18.5893\n",
            "Epoch: 177, Loss: 107.4801, Train: 18.3297, Val: 18.5890\n",
            "Epoch: 178, Loss: 107.3553, Train: 18.3296, Val: 18.5888\n",
            "Epoch: 179, Loss: 107.2659, Train: 18.3296, Val: 18.5886\n",
            "Epoch: 180, Loss: 107.1637, Train: 18.3296, Val: 18.5887\n",
            "Epoch: 181, Loss: 107.0591, Train: 18.3296, Val: 18.5889\n",
            "Epoch: 182, Loss: 106.9674, Train: 18.3296, Val: 18.5888\n",
            "Epoch: 183, Loss: 106.8545, Train: 18.3296, Val: 18.5888\n",
            "Epoch: 184, Loss: 106.7767, Train: 18.3296, Val: 18.5888\n",
            "Epoch: 185, Loss: 106.6716, Train: 18.3296, Val: 18.5890\n",
            "Epoch: 186, Loss: 106.5917, Train: 18.3296, Val: 18.5892\n",
            "Epoch: 187, Loss: 106.4926, Train: 18.3295, Val: 18.5896\n",
            "Epoch: 188, Loss: 106.4177, Train: 18.3295, Val: 18.5894\n",
            "Epoch: 189, Loss: 106.3235, Train: 18.3295, Val: 18.5892\n",
            "Epoch: 190, Loss: 106.2487, Train: 18.3294, Val: 18.5895\n",
            "Epoch: 191, Loss: 106.1595, Train: 18.3294, Val: 18.5896\n",
            "Epoch: 192, Loss: 106.0818, Train: 18.3295, Val: 18.5893\n",
            "Epoch: 193, Loss: 106.0032, Train: 18.3295, Val: 18.5894\n",
            "Epoch: 194, Loss: 105.9232, Train: 18.3294, Val: 18.5896\n",
            "Epoch: 195, Loss: 105.8539, Train: 18.3295, Val: 18.5896\n",
            "Epoch: 196, Loss: 105.7800, Train: 18.3295, Val: 18.5895\n",
            "Epoch: 197, Loss: 105.7146, Train: 18.3295, Val: 18.5900\n",
            "Epoch: 198, Loss: 105.6410, Train: 18.3295, Val: 18.5901\n",
            "Epoch: 199, Loss: 105.5787, Train: 18.3295, Val: 18.5899\n",
            "Epoch: 200, Loss: 105.5180, Train: 18.3295, Val: 18.5901\n",
            "Epoch: 201, Loss: 105.4515, Train: 18.3295, Val: 18.5904\n",
            "Epoch: 202, Loss: 105.3945, Train: 18.3295, Val: 18.5901\n",
            "Epoch: 203, Loss: 105.3429, Train: 18.3295, Val: 18.5907\n",
            "Epoch: 204, Loss: 105.3093, Train: 18.3294, Val: 18.5906\n",
            "Epoch: 205, Loss: 105.3204, Train: 18.3294, Val: 18.5912\n",
            "Epoch: 206, Loss: 105.3101, Train: 18.3294, Val: 18.5904\n",
            "Epoch: 207, Loss: 105.2177, Train: 18.3294, Val: 18.5912\n",
            "Epoch: 208, Loss: 105.0673, Train: 18.3294, Val: 18.5912\n",
            "Epoch: 209, Loss: 105.0251, Train: 18.3295, Val: 18.5905\n",
            "Epoch: 210, Loss: 105.0482, Train: 18.3294, Val: 18.5912\n",
            "Epoch: 211, Loss: 104.9673, Train: 18.3294, Val: 18.5914\n",
            "Epoch: 212, Loss: 104.8674, Train: 18.3294, Val: 18.5909\n",
            "Epoch: 213, Loss: 104.8547, Train: 18.3294, Val: 18.5911\n",
            "Epoch: 214, Loss: 104.8498, Train: 18.3294, Val: 18.5915\n",
            "Epoch: 215, Loss: 104.7309, Train: 18.3294, Val: 18.5917\n",
            "Epoch: 216, Loss: 104.6797, Train: 18.3294, Val: 18.5915\n",
            "Epoch: 217, Loss: 104.6870, Train: 18.3294, Val: 18.5914\n",
            "Epoch: 218, Loss: 104.6238, Train: 18.3293, Val: 18.5925\n",
            "Epoch: 219, Loss: 104.5492, Train: 18.3294, Val: 18.5920\n",
            "Epoch: 220, Loss: 104.4976, Train: 18.3294, Val: 18.5914\n",
            "Epoch: 221, Loss: 104.4969, Train: 18.3293, Val: 18.5927\n",
            "Epoch: 222, Loss: 104.4341, Train: 18.3293, Val: 18.5925\n",
            "Epoch: 223, Loss: 104.3659, Train: 18.3294, Val: 18.5917\n",
            "Epoch: 224, Loss: 104.3247, Train: 18.3293, Val: 18.5923\n",
            "Epoch: 225, Loss: 104.2895, Train: 18.3293, Val: 18.5925\n",
            "Epoch: 226, Loss: 104.2683, Train: 18.3293, Val: 18.5921\n",
            "Epoch: 227, Loss: 104.2182, Train: 18.3293, Val: 18.5922\n",
            "Epoch: 228, Loss: 104.1545, Train: 18.3293, Val: 18.5928\n",
            "Epoch: 229, Loss: 104.1154, Train: 18.3293, Val: 18.5924\n",
            "Epoch: 230, Loss: 104.0781, Train: 18.3293, Val: 18.5924\n",
            "Epoch: 231, Loss: 104.0461, Train: 18.3293, Val: 18.5933\n",
            "Epoch: 232, Loss: 104.0140, Train: 18.3293, Val: 18.5926\n",
            "Epoch: 233, Loss: 103.9705, Train: 18.3293, Val: 18.5932\n",
            "Epoch: 234, Loss: 103.9236, Train: 18.3293, Val: 18.5935\n",
            "Epoch: 235, Loss: 103.8759, Train: 18.3293, Val: 18.5934\n",
            "Epoch: 236, Loss: 103.8307, Train: 18.3293, Val: 18.5937\n",
            "Epoch: 237, Loss: 103.7843, Train: 18.3293, Val: 18.5938\n",
            "Epoch: 238, Loss: 103.7401, Train: 18.3293, Val: 18.5938\n",
            "Epoch: 239, Loss: 103.7000, Train: 18.3292, Val: 18.5942\n",
            "Epoch: 240, Loss: 103.6589, Train: 18.3292, Val: 18.5939\n",
            "Epoch: 241, Loss: 103.6179, Train: 18.3292, Val: 18.5953\n",
            "Epoch: 242, Loss: 103.5863, Train: 18.3292, Val: 18.5943\n",
            "Epoch: 243, Loss: 103.5406, Train: 18.3292, Val: 18.5944\n",
            "Epoch: 244, Loss: 103.5263, Train: 18.3292, Val: 18.5964\n",
            "Epoch: 245, Loss: 103.5872, Train: 18.3292, Val: 18.5945\n",
            "Epoch: 246, Loss: 103.8577, Train: 18.3292, Val: 18.5977\n",
            "Epoch: 247, Loss: 104.2066, Train: 18.3292, Val: 18.5939\n",
            "Epoch: 248, Loss: 104.0670, Train: 18.3292, Val: 18.5957\n",
            "Epoch: 249, Loss: 103.3662, Train: 18.3292, Val: 18.5983\n",
            "Epoch: 250, Loss: 103.5154, Train: 18.3291, Val: 18.5955\n",
            "Epoch: 251, Loss: 103.8032, Train: 18.3291, Val: 18.5951\n",
            "Epoch: 252, Loss: 103.3202, Train: 18.3291, Val: 18.5969\n",
            "Epoch: 253, Loss: 103.2812, Train: 18.3291, Val: 18.5971\n",
            "Epoch: 254, Loss: 103.5516, Train: 18.3291, Val: 18.5978\n",
            "Epoch: 255, Loss: 103.1336, Train: 18.3290, Val: 18.5964\n",
            "Epoch: 256, Loss: 103.1833, Train: 18.3290, Val: 18.5963\n",
            "Epoch: 257, Loss: 103.2568, Train: 18.3290, Val: 18.5991\n",
            "Epoch: 258, Loss: 102.9870, Train: 18.3290, Val: 18.5982\n",
            "Epoch: 259, Loss: 103.0486, Train: 18.3290, Val: 18.5966\n",
            "Epoch: 260, Loss: 103.0160, Train: 18.3289, Val: 18.5989\n",
            "Epoch: 261, Loss: 102.8881, Train: 18.3289, Val: 18.5987\n",
            "Epoch: 262, Loss: 102.8938, Train: 18.3290, Val: 18.5967\n",
            "Epoch: 263, Loss: 102.9037, Train: 18.3289, Val: 18.6000\n",
            "Epoch: 264, Loss: 102.7538, Train: 18.3289, Val: 18.5998\n",
            "Epoch: 265, Loss: 102.7847, Train: 18.3289, Val: 18.5959\n",
            "Epoch: 266, Loss: 102.7979, Train: 18.3289, Val: 18.5994\n",
            "Epoch: 267, Loss: 102.6297, Train: 18.3289, Val: 18.6013\n",
            "Epoch: 268, Loss: 102.6357, Train: 18.3288, Val: 18.5987\n",
            "Epoch: 269, Loss: 102.6325, Train: 18.3288, Val: 18.5989\n",
            "Epoch: 270, Loss: 102.5422, Train: 18.3288, Val: 18.6008\n",
            "Epoch: 271, Loss: 102.4834, Train: 18.3288, Val: 18.5996\n",
            "Epoch: 272, Loss: 102.4697, Train: 18.3288, Val: 18.6002\n",
            "Epoch: 273, Loss: 102.4417, Train: 18.3288, Val: 18.6013\n",
            "Epoch: 274, Loss: 102.3713, Train: 18.3287, Val: 18.6009\n",
            "Epoch: 275, Loss: 102.3261, Train: 18.3287, Val: 18.6009\n",
            "Epoch: 276, Loss: 102.3098, Train: 18.3287, Val: 18.6017\n",
            "Epoch: 277, Loss: 102.2833, Train: 18.3287, Val: 18.6018\n",
            "Epoch: 278, Loss: 102.2205, Train: 18.3287, Val: 18.6010\n",
            "Epoch: 279, Loss: 102.1766, Train: 18.3287, Val: 18.6030\n",
            "Epoch: 280, Loss: 102.1516, Train: 18.3287, Val: 18.6028\n",
            "Epoch: 281, Loss: 102.1267, Train: 18.3286, Val: 18.6021\n",
            "Epoch: 282, Loss: 102.0883, Train: 18.3287, Val: 18.6040\n",
            "Epoch: 283, Loss: 102.0442, Train: 18.3286, Val: 18.6025\n",
            "Epoch: 284, Loss: 101.9937, Train: 18.3286, Val: 18.6043\n",
            "Epoch: 285, Loss: 101.9538, Train: 18.3286, Val: 18.6045\n",
            "Epoch: 286, Loss: 101.9270, Train: 18.3286, Val: 18.6039\n",
            "Epoch: 287, Loss: 101.9021, Train: 18.3286, Val: 18.6052\n",
            "Epoch: 288, Loss: 101.8737, Train: 18.3285, Val: 18.6037\n",
            "Epoch: 289, Loss: 101.8400, Train: 18.3286, Val: 18.6058\n",
            "Epoch: 290, Loss: 101.7974, Train: 18.3285, Val: 18.6045\n",
            "Epoch: 291, Loss: 101.7539, Train: 18.3285, Val: 18.6065\n",
            "Epoch: 292, Loss: 101.7095, Train: 18.3285, Val: 18.6051\n",
            "Epoch: 293, Loss: 101.6726, Train: 18.3285, Val: 18.6066\n",
            "Epoch: 294, Loss: 101.6395, Train: 18.3285, Val: 18.6060\n",
            "Epoch: 295, Loss: 101.6213, Train: 18.3285, Val: 18.6070\n",
            "Epoch: 296, Loss: 101.6239, Train: 18.3285, Val: 18.6065\n",
            "Epoch: 297, Loss: 101.6606, Train: 18.3285, Val: 18.6077\n",
            "Epoch: 298, Loss: 101.7281, Train: 18.3284, Val: 18.6060\n",
            "Epoch: 299, Loss: 101.8373, Train: 18.3285, Val: 18.6105\n",
            "Epoch: 300, Loss: 101.8813, Train: 18.3284, Val: 18.6041\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    test_data = test_data.to(device)\n",
        "    pred = model(test_data.x_dict, test_data.edge_index_dict,\n",
        "                 test_data['user', 'station'].edge_label_index)\n",
        "    # pred = pred.clamp(min=0, max=5)\n",
        "    target = test_data['user', 'station'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    print(f'Test RMSE: {rmse:.4f}')\n",
        "\n",
        "userId = test_data['user', 'station'].edge_label_index[0].cpu().numpy()\n",
        "stationId = test_data['user', 'station'].edge_label_index[1].cpu().numpy()\n",
        "pred = pred.cpu().numpy()\n",
        "target = target.cpu().numpy()\n",
        "\n",
        "print(pd.DataFrame({'userId': userId, 'stationId': stationId, 'demand': pred, 'target': target}))"
      ],
      "metadata": {
        "id": "QT_NONRIJwE6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e072520f-1e1f-41f2-8d7e-178157b33d0c"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test RMSE: 11.1323\n",
            "      userId  stationId     demand     target\n",
            "0       1124        331   5.598994   3.890000\n",
            "1          0        181  14.600853  10.190000\n",
            "2       1035       1581   8.787170   1.800000\n",
            "3          0         15  16.132374  30.400000\n",
            "4       1544       1463   9.652048   3.820000\n",
            "...      ...        ...        ...        ...\n",
            "7280       0         41  19.253338  31.940001\n",
            "7281    1138       1216  41.602848  54.189999\n",
            "7282     862        141  27.064394  33.240002\n",
            "7283       0         81  15.051769  12.130000\n",
            "7284       0         90  19.834482   9.300000\n",
            "\n",
            "[7285 rows x 4 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "userId=1\n",
        "chargerId=5"
      ],
      "metadata": {
        "id": "JXakz2eQyeAi"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_user_index = unique_user_id[unique_user_id['UserID'] == userId]['mappedUserId'].values[0]\n",
        "new_station_index = unique_movie_id[unique_movie_id['ChargerID'] == chargerId]['mappedMovieId'].values[0]\n",
        "new_edge_index = torch.tensor([[new_user_index], [new_station_index]])"
      ],
      "metadata": {
        "id": "PtNOXs2yxqNQ"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():  # No need to calculate gradients for prediction\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    pred = model(\n",
        "        train_data.x_dict,  # Assuming you want to use the training data's features\n",
        "        train_data.edge_index_dict,  # and connectivity for context\n",
        "        new_edge_index.to(device)  # The new edge to predict\n",
        "    )\n",
        "    print(f\"Predicted demand for User {userId} and Charger {chargerId}: {pred.item()}\")"
      ],
      "metadata": {
        "id": "4_8XS3vUyAr3",
        "outputId": "37ae1ad0-ecb8-41a1-fbc7-215cac43c76a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted demand for User 1 and Charger 5: 34.144615173339844\n"
          ]
        }
      ]
    }
  ]
}